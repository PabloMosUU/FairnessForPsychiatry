{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation exploration\n",
    "\n",
    "This notebook analyzes the results of cross-validation and presents them in the format of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from CV import get_latex, get_latex_performance, get_latex_fairness\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CV/CV5_no_protected_attribute/cross_validation.csv', sep=';')\n",
    "MODEL_NAMES = ('logreg', 'rf', 'logregreweight', 'rfreweight', 'prejudiceremover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_stdev_for_single_model(selection: pd.DataFrame, model: str, deltas=False) -> pd.DataFrame:\n",
    "    means = selection.mean()\n",
    "    stds = selection.std()\n",
    "    mean_std = pd.concat([means, stds], axis=1).rename(columns={0: 'Mean', 1: 'StdDev'})\n",
    "    # The following check for statistical significance only applies to deltas\n",
    "    if deltas:\n",
    "        statistically_significant = mean_std[mean_std.apply(lambda row: row['StdDev'] * 2 < abs(row['Mean']), 1)]\n",
    "        if len(statistically_significant) > 0:\n",
    "            print('Statistical significance in ' + model, statistically_significant.index)\n",
    "        else:\n",
    "            print('No statistically significant rows')\n",
    "    mean_std[model] = mean_std.apply(lambda row: ' +/- '.join(['{:.3f}'.format(row[el]) for el in ('Mean', 'StdDev')]), 1)\n",
    "    report = mean_std.drop(columns=['Mean', 'StdDev']).transpose()\n",
    "    report.drop(columns=[el for el in ('Bias Mitigator', 'fold') if el in report.columns], inplace=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rows(df: pd.DataFrame, model: str) -> pd.DataFrame:\n",
    "    if model in ('logreg', 'rf'):\n",
    "        bias_mitigator = lambda frame: frame['Bias Mitigator'].isnull()\n",
    "    else:\n",
    "        bias_mitigator = lambda frame: frame['Bias Mitigator'] == ('Reweighting' if model.endswith('reweight') else 'Prejudice Remover')\n",
    "    clf = 'Random Forest' if model.startswith('rf') else 'Logistic Regression'\n",
    "    return df[(bias_mitigator(df)) & (df['Classifier'] == clf)]\n",
    "\n",
    "def get_mean_stdev(model: str) -> pd.DataFrame:\n",
    "    selection = select_rows(df, model)\n",
    "    return get_mean_stdev_for_single_model(selection, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_name(model_name: str) -> str:\n",
    "    if model_name.startswith('rf'):\n",
    "        return 'Random Forest'\n",
    "    else:\n",
    "        return 'Logistic Regression'\n",
    "    \n",
    "def get_mitigator_name(model_name: str) -> str:\n",
    "    if model_name.endswith('reweight'):\n",
    "        return 'Reweighing'\n",
    "    elif model_name == 'prejudiceremover':\n",
    "        return 'Prejudice Remover'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = pd.concat([get_mean_stdev(el) for el in MODEL_NAMES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table.reset_index(drop=False, inplace=True)\n",
    "metrics_table['Classifier'] = metrics_table['index'].apply(get_classifier_name)\n",
    "metrics_table['Bias Mitigator'] = metrics_table['index'].apply(get_mitigator_name)\n",
    "metrics_table.drop(columns=['index'], errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between original model and bias mitigators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_clf = []\n",
    "for clf in df['Classifier'].unique():\n",
    "    clf_df = df[df['Classifier'] == clf].reset_index(drop=True)\n",
    "    df_by_fold = []\n",
    "    for fold in clf_df['fold'].unique():\n",
    "        clf_fold_df = clf_df[clf_df['fold'] == fold].reset_index(drop=True)\n",
    "        mitigators = []\n",
    "        deltas = defaultdict(list)\n",
    "        for mitigator in clf_fold_df[clf_fold_df['Bias Mitigator'].notnull()]['Bias Mitigator'].unique():\n",
    "            mitigators.append(mitigator)\n",
    "            for metric in clf_fold_df.columns:\n",
    "                if metric in ('Classifier', 'Bias Mitigator', 'fold'):\n",
    "                    continue\n",
    "                effect_metric_values = clf_fold_df[clf_fold_df['Bias Mitigator'] == mitigator][metric].tolist()\n",
    "                baseline_metric_values = clf_fold_df[clf_fold_df['Bias Mitigator'].isnull()][metric].tolist()\n",
    "                assert len(effect_metric_values) == 1 and len(baseline_metric_values) == 1\n",
    "                delta = effect_metric_values[0] - baseline_metric_values[0]\n",
    "                deltas[metric].append(delta)\n",
    "        delta_df = pd.DataFrame()\n",
    "        delta_df['Bias Mitigator'] = mitigators\n",
    "        for metric, delta in deltas.items():\n",
    "            delta_df[metric] = delta\n",
    "        delta_df['fold'] = fold\n",
    "        df_by_fold.append(delta_df)\n",
    "    delta_all_folds = pd.concat(df_by_fold)\n",
    "    mean_std = []\n",
    "    for lbl, grp in delta_all_folds.groupby('Bias Mitigator'):\n",
    "        mean_std_for_mitigator = get_mean_stdev_for_single_model(grp, clf + '_' + lbl, deltas=True)\n",
    "        mean_std_for_mitigator['Bias Mitigator'] = lbl\n",
    "        mean_std.append(mean_std_for_mitigator)\n",
    "    mean_std = pd.concat(mean_std)\n",
    "    mean_std['Classifier'] = clf\n",
    "    by_clf.append(mean_std)\n",
    "final_diffs = pd.concat(by_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format tables for Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in get_latex_performance(metrics_table).split('\\n'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in get_latex_fairness(metrics_table).split('\\n'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in get_latex_performance(final_diffs, True).split('\\n'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in get_latex_fairness(final_diffs, True).split('\\n'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
