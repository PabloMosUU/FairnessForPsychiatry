{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the dataset(s) to be used for classification, starting from the datasets that contain the basic information about patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "DATA_DIR = '/media/bigdata/10. Stages/3. Afgerond/2020-08 Jesse Kuiper/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting usefull var \n",
    "admission_columns = [\"OpnameID\", \"PseudoID\",\"AfdelingOmschrijving\", \"Opnamedatum\",  \"Ontslagdatum\",  \"Opnametijd\", \n",
    "                     \"Ontslagtijd\",    \"Spoed\",  \"EersteOpname\",  \"Geslacht\", \"Leeftijd_opname\", \n",
    "                     \"OpnamestatusOmschrijving\", \"Duur\"]\n",
    "\n",
    "administering_columns = [\"PseudoID\", \"VoorschriftID\", \"ATC_code_omschr\", \"Medicijnnaam_ingevuld\",\"Dosis\", \n",
    "                         \"Eenheid\", \"ToedienDatum\", \"ToedienTijd\", \"Toegediend\", \"DosisVerbruikt\", \n",
    "                         \"DosisOrigineel\", \"ToedieningIsOpgeschort\", \"NietToegediend\"  ]\n",
    "\n",
    "dbc_columns = [ \"PseudoID\", \"dbcnummer\",\"Startdatum\", \"Einddatum\" ,\"hoofddiagnose_groep\", \"zorgvraagzwaarte\", \n",
    "               \"MeervoudigeProblematiekInd\", \"persoonlijkheidsstoornis\", \"Opname\", \"DiagnoseDatum\" ]\n",
    "\n",
    "violent_columns = [\"PseudoID\", \"hantering_datum\", \"begin_incident\"]\n",
    "\n",
    "patient_columns = [\"PseudoID\", \"Leeftijd_startdatum_dossier\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load opnamens\n",
    "admission = pd.read_csv(DATA_DIR + \"werkbestanden-opnames/latest/werkbestand_opnames.csv\", sep=';', \n",
    "                        usecols=admission_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load administered\n",
    "administering = pd.read_csv(DATA_DIR + \"werkbestanden-medicatie/latest/werkbestand_medicatie_toediening.csv\", sep=';',\n",
    "                        decimal=',', usecols=administering_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dbc\n",
    "dbc = pd.read_csv(DATA_DIR + \"werkbestanden-dbc/latest/werkbestand_dbc.csv\", sep=';', usecols=dbc_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load map\n",
    "violent = pd.read_csv(DATA_DIR + \"werkbestanden-map/latest/werkbestand_map.csv\", sep=';', usecols=violent_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load patient or patient uniek\n",
    "patient = pd.read_csv(DATA_DIR + \"werkbestanden-patient/latest/werkbestand_patient_uniek.csv\", sep=';', \n",
    "                  usecols=patient_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter datasets and fix null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove incomplete admissions \n",
    "admission = admission[admission.OpnamestatusOmschrijving == \"Ontslagen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for na values\n",
    "assert admission.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change Opnamedatum Ontslagdatum to date times        \n",
    "admission[\"OpnamedatumTijd\"] = pd.to_datetime(admission[\"Opnamedatum\"] + ' ' + admission[\"Opnametijd\"])\n",
    "admission[\"OntslagdatumTijd\"] = pd.to_datetime(admission[\"Ontslagdatum\"] + ' ' + admission[\"Ontslagtijd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DateTime checks for the agression and the dbc\n",
    "# these datetimes make sure it only covers the \n",
    "# If the duration of admission is less than the time check, it will take the whole admission\n",
    "admission[\"DaysF\"] = np.where(admission[\"Duur\"]>= 14, 14, admission[\"Duur\"])\n",
    "admission[\"DaysP\"] = np.where(admission[\"Duur\"]>= 3, 3, admission[\"Duur\"])\n",
    "\n",
    "# create date time checks #these should have a max value\n",
    "admission[\"DateTimeCheckF\"] = admission[\"OpnamedatumTijd\"] + pd.to_timedelta(admission[\"DaysF\"], unit='d')\n",
    "admission[\"DateTimeCheckP\"] = admission[\"OpnamedatumTijd\"] + pd.to_timedelta(admission[\"DaysP\"], unit='d')\n",
    "\n",
    "afd = [\"Klin. Affectieve & Psychotische stoorn.\",\"Klinische Acuut & Intensieve Zorg\",\"Klin.Acuut & Intensieve. Zorg Jeugd\", \"Klin Diagn & Vroege Psychose\"]\n",
    "\n",
    "# AfdelingOmschrijving\n",
    "adm_afd = pd.get_dummies(admission[\"AfdelingOmschrijving\"])\n",
    "adm_afd_sel = pd.concat([admission, adm_afd[afd]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adm_afd_sel[\"AfdelingOmschrijving\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create admission1 - 8663, admission2 - 3192 and admission3 - 4685\n",
    "admission1 = adm_afd_sel.copy()\n",
    "admission2 = adm_afd_sel[admission[\"Duur\"]> 14].reset_index().copy()\n",
    "admission3 = adm_afd_sel[admission[\"Duur\"]> 3].reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All discharged admissions from the four nursing wards:', len(admission1))\n",
    "print('Only admissions lasting 3 or more days:', len(admission3))\n",
    "print('Only admissions lasting 14 or more days:', len(admission2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change NaN in hoofddiagnose_groep to \"Lege hoofddiagnose\" as this is already a variable in the table with the same meaning\n",
    "dbc[\"hoofddiagnose_groep\"] = dbc[\"hoofddiagnose_groep\"].replace(np.nan, \"Lege hoofddiagnose\", regex=True)\n",
    "dbc[\"hoofddiagnose_groep\"] = dbc[\"hoofddiagnose_groep\"].str.replace(\"Bijkomende codes/geen diagnose\",\"Lege hoofddiagnose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a diagnose date\n",
    "# this is a limitation to be mentioned in the paper\n",
    "def get_diagnosis_date(row):\n",
    "    if type(row.DiagnoseDatum) == str:\n",
    "        return row.DiagnoseDatum\n",
    "    elif type(row.Einddatum) == str:\n",
    "        return row.Einddatum\n",
    "    else:\n",
    "        return row.Startdatum\n",
    "\n",
    "dbc[\"diagnosis_date\"] = dbc.apply(lambda row: get_diagnosis_date(row), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbc.drop(columns=['DiagnoseDatum', 'Einddatum', 'Startdatum'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that do not have a PseudoID, as there is no way to couple them with admissions\n",
    "dbc = dbc[dbc['PseudoID'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dbc.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violence incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop rows that do not have a PseudoID, as there is no way to couple them with admissions\n",
    "violent = violent[violent['PseudoID'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change hantering_datum to date time with begin_incident\n",
    "violent[\"hantering_datumTijd\"] = pd.to_datetime(violent[\"hantering_datum\"] + ' ' + violent[\"begin_incident\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert violent.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only patients for which we also have admissions\n",
    "patient = admission[['PseudoID']].merge(patient, on='PseudoID', how='left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(patient) == admission['PseudoID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert patient.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Administered medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are only interested in administered medicine\n",
    "administering = administering[administering[\"Toegediend\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of agreed upon tranquilizers\n",
    "AllTranq = [\"lorazepam\", \"oxazepam\",\"diazepam\", \"zopiclone\", \"temazepam\" , \"midazolam\" , \"zolpidem\" , \"alprazolam\",\n",
    "            \"bromazepam\", \"lormetazepam\", \"clorazepate potassium\", \"nitrazepam\", \"flurazepam\", \"clobazam\", \n",
    "            \"chlordiazepoxide\", \"brotizolam\"]\n",
    "\n",
    "administering = administering[administering[\"ATC_code_omschr\"].isin(AllTranq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 administering does not contain a toediendatum and toedientijd (corrupted data)\n",
    "administering = administering.dropna(subset=[\"ToedienDatum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert administering.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datetime\n",
    "administering[\"ToedienDatumTijd\"] = pd.to_datetime(administering[\"ToedienDatum\"] + ' ' + administering[\"ToedienTijd\"])\n",
    "administering.drop(columns=['ToedienDatum', 'ToedienTijd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge administering\n",
    "# based on the dosis\n",
    "TranqDict = {\n",
    "    \"lorazepam\": 5,\n",
    "    \"oxazepam\": 0.33,\n",
    "    \"diazepam\": 1,\n",
    "    \"zopiclone\": 1.33,\n",
    "    \"temazepam\": 1,\n",
    "    \"midazolam\": 10,\n",
    "    \"zolpidem\": 1,\n",
    "    \"alprazolam\": 10,\n",
    "    \"bromazepam\": 1,\n",
    "    \"lormetazepam\": 10,\n",
    "    \"clorazepate potassium\": 0.75,\n",
    "    \"nitrazepam\": 1,\n",
    "    \"flurazepam\": 0.33,\n",
    "    \"clobazam\": 0.5,\n",
    "    \"chlordiazepoxide\": 0.5,\n",
    "    \"brotizolam\": 40,\n",
    "}\n",
    "\n",
    "def InDiazepam(row):\n",
    "    tranquilizer_multiplier = TranqDict\n",
    "    omschr = row['ATC_code_omschr']\n",
    "    dosis = row['Dosis']\n",
    "    return tranquilizer_multiplier[omschr] * dosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(TranqDict.keys()) == set(AllTranq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "administering[\"DoseDiazepam\"] = administering.apply(InDiazepam, axis=1)\n",
    "administering.drop(columns=['ATC_code_omschr', 'Dosis'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Join tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient onto Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first add the patient data to the opnamens\n",
    "def get_adm_pat(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    adm_adm1 = frame.merge(patient, on=\"PseudoID\", how=\"left\")\n",
    "    assert np.sum(adm_adm1.isnull().sum().values) == 0\n",
    "    assert len(adm_adm1) == len(frame)\n",
    "    return adm_adm1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge patient data with admission data\n",
    "adm_pat1 = get_adm_pat(admission1)  \n",
    "\n",
    "adm_pat2 = get_adm_pat(admission2)\n",
    "\n",
    "adm_pat3 = get_adm_pat(admission3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violence incidents onto Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge violence data, this is where the datasets start to differ (time period where you count violence incidents)\n",
    "# give violence data an unique identifier\n",
    "violent[\"IncidentID\"] = np.arange(len(violent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataset with mapdata\n",
    "map_adm1 = adm_pat1.merge(violent[[\"PseudoID\", \"IncidentID\", \"hantering_datumTijd\"]], how=\"left\", on=\"PseudoID\")\n",
    "map_adm2 = adm_pat2.merge(violent[[\"PseudoID\", \"IncidentID\", \"hantering_datumTijd\"]], how=\"left\", on=\"PseudoID\")\n",
    "map_adm3 = adm_pat3.merge(violent[[\"PseudoID\", \"IncidentID\", \"hantering_datumTijd\"]], how=\"left\", on=\"PseudoID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# whole dataset\n",
    "opname_ids, incidents_during_admission, incidents_before_admission = [], [], []\n",
    "for opname_id, grp in map_adm1.groupby(\"OpnameID\"):\n",
    "    # opname_id -> single OpnameID from adm_map table                                                                                                                                                      \n",
    "    # grp -> a dataframe containing only the rows that have OpnameID == opname_id                                                                                                                          \n",
    "    opname_ids.append(opname_id)\n",
    "    if len(grp[grp[\"IncidentID\"].notnull()]) == 0:\n",
    "        # No incidents                                                                                                                                                                                     \n",
    "        incidents_during_admission.append(0)\n",
    "        incidents_before_admission.append(0)\n",
    "    else:\n",
    "        # At least one incident                                                                                                                                                                                                                                                                                                                                    \n",
    "        n_during = len(grp[grp.apply(lambda row: row.OntslagdatumTijd >= row.hantering_datumTijd >= row.OpnamedatumTijd, 1)])\n",
    "        n_before = len(grp[grp.apply(lambda row: row.hantering_datumTijd < row.OpnamedatumTijd, 1)])\n",
    "        incidents_during_admission.append(n_during)\n",
    "        incidents_before_admission.append(n_before)\n",
    "\n",
    "# Create a new incidents-counts dataframe\n",
    "admission_incidents = pd.DataFrame()\n",
    "admission_incidents[\"OpnameID\"] = opname_ids\n",
    "admission_incidents[\"incidents_during_admission\"] = incidents_during_admission\n",
    "admission_incidents[\"incidents_before_admission\"] = incidents_before_admission\n",
    "assert len(admission_incidents) == len(adm_pat1)\n",
    "\n",
    "# Merge the incidents-counts dataframe onto opnames\n",
    "adm_map1 = adm_pat1.merge(admission_incidents, on=\"OpnameID\", how=\"inner\")\n",
    "assert len(adm_map1) == len(adm_pat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dataset2 \n",
    "opname_ids, incidents_during_admission, incidents_before_admission = [], [], []\n",
    "for opname_id, grp in map_adm2.groupby(\"OpnameID\"):\n",
    "    # opname_id -> single OpnameID from adm_map table                                                                                                                                                      \n",
    "    # grp -> a dataframe containing only the rows that have OpnameID == opname_id                                                                                                                          \n",
    "    opname_ids.append(opname_id)\n",
    "    if len(grp[grp[\"IncidentID\"].notnull()]) == 0:\n",
    "        # No incidents                                                                                                                                                                                     \n",
    "        incidents_during_admission.append(0)\n",
    "        incidents_before_admission.append(0)\n",
    "    else:\n",
    "        # At least one incident                                                                                                                                                                                                                                                                                                                                    \n",
    "        n_during = len(grp[grp.apply(lambda row: row.DateTimeCheckF >= row.hantering_datumTijd >= row.OpnamedatumTijd, 1)])\n",
    "        # TODO: the following comparison should be strictly less than\n",
    "        n_before = len(grp[grp.apply(lambda row: row.hantering_datumTijd <= row.OpnamedatumTijd, 1)])\n",
    "        incidents_during_admission.append(n_during)\n",
    "        incidents_before_admission.append(n_before)\n",
    "\n",
    "# Create a new incidents-counts dataframe\n",
    "admission_incidents = pd.DataFrame()\n",
    "admission_incidents[\"OpnameID\"] = opname_ids\n",
    "admission_incidents[\"incidents_during_admission\"] = incidents_during_admission\n",
    "admission_incidents[\"incidents_before_admission\"] = incidents_before_admission\n",
    "assert len(admission_incidents) == len(adm_pat2)\n",
    "\n",
    "# Merge the incidents-counts dataframe onto opnames\n",
    "adm_map2 = adm_pat2.merge(admission_incidents, on=\"OpnameID\", how=\"inner\")\n",
    "assert len(adm_map2) == len(adm_pat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  dataset3 \n",
    "opname_ids, incidents_during_admission, incidents_before_admission = [], [], []\n",
    "for opname_id, grp in map_adm3.groupby(\"OpnameID\"):\n",
    "    # opname_id -> single OpnameID from adm_map table                                                                                                                                                      \n",
    "    # grp -> a dataframe containing only the rows that have OpnameID == opname_id                                                                                                                          \n",
    "    opname_ids.append(opname_id)\n",
    "    if len(grp[grp[\"IncidentID\"].notnull()]) == 0:\n",
    "        # No incidents                                                                                                                                                                                     \n",
    "        incidents_during_admission.append(0)\n",
    "        incidents_before_admission.append(0)\n",
    "    else:\n",
    "        # At least one incident                                                                                                                                                                                                                                                                                                                                    \n",
    "        n_during = len(grp[grp.apply(lambda row: row.DateTimeCheckP >= row.hantering_datumTijd >= row.OpnamedatumTijd, 1)])\n",
    "        n_before = len(grp[grp.apply(lambda row: row.hantering_datumTijd < row.OpnamedatumTijd, 1)])\n",
    "        incidents_during_admission.append(n_during)\n",
    "        incidents_before_admission.append(n_before)\n",
    "\n",
    "# Create a new incidents-counts dataframe\n",
    "admission_incidents = pd.DataFrame()\n",
    "admission_incidents[\"OpnameID\"] = opname_ids\n",
    "admission_incidents[\"incidents_during_admission\"] = incidents_during_admission\n",
    "admission_incidents[\"incidents_before_admission\"] = incidents_before_admission\n",
    "assert len(admission_incidents) == len(adm_pat3)\n",
    "\n",
    "# Merge the incidents-counts dataframe onto opnames\n",
    "adm_map3 = adm_pat3.merge(admission_incidents, on=\"OpnameID\", how=\"inner\")\n",
    "assert len(adm_map3) == len(adm_pat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### DBC onto Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to merge adm_dbc with the right dbc\n",
    "\n",
    "hoofddiagnoses = [\n",
    "    \"Aandachtsstoornis\",\n",
    "    \"Andere problemen die een reden van zorg kunnen zijn\",\n",
    "    \"Angststoornissen\",\n",
    "    \"Autismespectrumstoornis\",\n",
    "    \"Bipolaire stoornissen\",\n",
    "    \"Cognitieve stoornissen\",\n",
    "    \"Depressieve stoornissen\",\n",
    "    \"Dissociatieve stoornissen\",\n",
    "    \"Gedragsstoornissen\",\n",
    "    \"Middelgerelateerde en verslavingsstoornissen\",\n",
    "    \"Obsessieve-compulsieve en verwante stoornissen\",\n",
    "    \"Overige psychische stoornissen\",\n",
    "    \"Overige stoornissen op zuigelingen of kinderleeftijd\",\n",
    "    \"Persoonlijkheidsstoornissen\",\n",
    "    \"Psychische stoornissen door een somatische aandoening\",\n",
    "    \"Schizofrenie en andere psychotische stoornissen\",\n",
    "    \"Somatisch-symptoomstoornis en verwante stoornissen\",\n",
    "    \"Trauma- en stressorgerelateerde stoornissen\",\n",
    "    \"Voedings- en eetstoornissen\",]\n",
    "\n",
    "def get_adm_dbc(dataset: int, frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataset_end_date_column = {1: 'OntslagdatumTijd', 2: 'DateTimeCheckF', 3: 'DateTimeCheckP'}\n",
    "    end_date = dataset_end_date_column[dataset]\n",
    "    adm_dbc = frame.merge(dbc, how='inner', on='PseudoID')\n",
    "    \n",
    "    # Opnamedatum, Ontslagdatum, Startdatum, Einddatum\n",
    "    adm_dbc[\"diagnosis_date\"]= pd.to_datetime(adm_dbc[\"diagnosis_date\"])\n",
    "    \n",
    "    adm_dbc['DbcWithin'] = adm_dbc.apply(lambda row: int(row.OpnamedatumTijd <= row.diagnosis_date <= row[end_date]), 1)\n",
    "    \n",
    "    # selecting only the rows that are DbcWithin\n",
    "    dbc_within = adm_dbc[adm_dbc.DbcWithin != 0]\n",
    "    \n",
    "    # create columns of interesting data, this could not be dont in one go\n",
    "    dbc_within2 = dbc_within[[\"OpnameID\", \"hoofddiagnose_groep\"]]\n",
    "    \n",
    "    # only select with a diagnoses\n",
    "    dbc_within2 = dbc_within2[dbc_within2[\"hoofddiagnose_groep\"] != \"Lege hoofddiagnose\"]\n",
    "    dbc_within2 = dbc_within2.drop_duplicates()\n",
    "    \n",
    "    # create columns of the values of hoofddiagnose_groep\n",
    "    diagnoses = pd.get_dummies(dbc_within2[\"hoofddiagnose_groep\"])\n",
    "\n",
    "    dbc_within3 = pd.concat([dbc_within2, diagnoses], axis=1)\n",
    "    \n",
    "    if \"Overige psychische stoornissen\" not in dbc_within3:\n",
    "        dbc_within3[\"Overige psychische stoornissen\"] = np.nan\n",
    "            \n",
    "    dbc_hd = pd.DataFrame(dbc_within3.groupby('OpnameID')[hoofddiagnoses].max())\n",
    "    \n",
    "    # mvpi and persoonlijkheidsstoornis\n",
    "    dbc_mp = pd.DataFrame(dbc_within.groupby('OpnameID')[['MeervoudigeProblematiekInd', \n",
    "                                                          'persoonlijkheidsstoornis']].max().reset_index())\n",
    "    \n",
    "    # zorgvraagtevraag\n",
    "    dbc_zv = pd.DataFrame(dbc_within.assign(ZorgvraagzwaarteMin = dbc_within['zorgvraagzwaarte'].abs(),\n",
    "                                            ZorgvraagzwaarteMax = dbc_within['zorgvraagzwaarte'].abs())\n",
    "                          .groupby('OpnameID')\n",
    "                          .agg({'ZorgvraagzwaarteMin':'min','ZorgvraagzwaarteMax':'max'}).reset_index())\n",
    "    assert len(dbc_mp) == dbc_within.OpnameID.nunique() and len(dbc_zv) == len(dbc_mp)\n",
    "    \n",
    "    #merge interesting columns\n",
    "    ds_dbc = dbc_mp.merge(dbc_zv, how=\"inner\", on=\"OpnameID\")\n",
    "    \n",
    "    #check that you didn't insert unnecessary rows\n",
    "    assert len(dbc_mp) == len(ds_dbc)\n",
    "    \n",
    "    #merge hoofddiagnoses\n",
    "    ds1_dbc = ds_dbc.merge(dbc_hd, how=\"inner\", on=\"OpnameID\")\n",
    "    \n",
    "    #merge interesting columns with adm_map\n",
    "    adm_dbc = frame.merge(ds1_dbc, how= \"left\", on=\"OpnameID\")\n",
    "    \n",
    "    #check that you still have the same number of admissions\n",
    "    assert len(adm_dbc) == len(frame)\n",
    "    \n",
    "    #fill na values\n",
    "    adm_dbc = adm_dbc.replace(np.nan,0)\n",
    "    \n",
    "    # test for missing values\n",
    "    assert np.sum(adm_dbc.isnull().sum().values) == 0\n",
    "    return adm_dbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dbc based on date contraints with adm_map1\n",
    "adm_dbc1 = get_adm_dbc(1,adm_map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dbc based on date contraints with adm_map2\n",
    "adm_dbc2 = get_adm_dbc(2,adm_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dbc based on date contraints with adm_map3\n",
    "adm_dbc3 = get_adm_dbc(3,adm_map3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Administered medication onto Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create past and future tranq prescriptions\n",
    "\n",
    "var_pat = [\"PseudoID\",\n",
    "        \"Spoed\",\n",
    "        \"EersteOpname\",\n",
    "        \"Geslacht\",\n",
    "        \"Leeftijd_opname\",\n",
    "        \"Duur\",\n",
    "        \"Leeftijd_startdatum_dossier\",\n",
    "        \"incidents_during_admission\",\n",
    "        \"incidents_before_admission\",\n",
    "        \"MeervoudigeProblematiekInd\",\n",
    "        \"persoonlijkheidsstoornis\",\n",
    "        \"ZorgvraagzwaarteMin\",\n",
    "        \"ZorgvraagzwaarteMax\",\n",
    "        \"DoseDiazepam\",\n",
    "        \"DoseDiazepamPre\",\n",
    "        \"DoseDiazepamPost\",   \n",
    "]\n",
    "\n",
    "# TODO: rename this variable\n",
    "UsefullVariables = var_pat + afd + hoofddiagnoses\n",
    "\n",
    "# left join on PseudoID\n",
    "# has no end date restriction for the post prescriptions\n",
    "# TODO: rename this method\n",
    "def get_adm_dbc(dataset: int, frame ):\n",
    "    dataset_end_date_column = {1: 'OntslagdatumTijd', 2: 'DateTimeCheckF', 3: 'DateTimeCheckP'}\n",
    "    end_date = dataset_end_date_column[dataset]\n",
    "    adm_adm1 = frame.merge(administering[[\"PseudoID\", \"ToedienDatumTijd\", \"DoseDiazepam\" ]], how=\"left\", \n",
    "                           on=\"PseudoID\")  \n",
    "\n",
    "    # remove rows where the ToedienDatumTijd is outside of the OpnamedatumTijd and OntslagdatumTijd\n",
    "    adm_adm1 = adm_adm1[adm_adm1[\"ToedienDatumTijd\"] >= adm_adm1[\"OpnamedatumTijd\"]]\n",
    "    adm_adm1 = adm_adm1[adm_adm1[\"ToedienDatumTijd\"] <= adm_adm1[\"OntslagdatumTijd\"]]\n",
    "\n",
    "    # create past and future prescriptions\n",
    "    adm_adm1[\"Past\"] = adm_adm1.apply(lambda row: int(row.ToedienDatumTijd <= row[end_date] and \\\n",
    "                                                      row.ToedienDatumTijd >= row.OpnamedatumTijd), 1)\n",
    "\n",
    "    # diazepam prescribed in the past\n",
    "    adm_adm1[\"DoseDiazepamPre\"] = np.where(adm_adm1[\"Past\"]== 1, adm_adm1[\"DoseDiazepam\"], 0 )\n",
    "\n",
    "    # diazepam prescribed in the future\n",
    "    adm_adm1[\"DoseDiazepamPost\"] = np.where(adm_adm1[\"Past\"]== 0, adm_adm1[\"DoseDiazepam\"], 0 )\n",
    "    \n",
    "    # groupby\n",
    "    groupby_columns = [\"OpnameID\", \"OpnamedatumTijd\", \"OntslagdatumTijd\"]\n",
    "    selection_columns = [\"DoseDiazepam\",\"DoseDiazepamPre\",\"DoseDiazepamPost\"]\n",
    "    adm_adm2 = pd.DataFrame(adm_adm1.groupby(groupby_columns)[selection_columns].sum())\n",
    "                                      \n",
    "    Dataset = frame.merge(adm_adm2, on=[\"OpnameID\", \"OpnamedatumTijd\",\"OntslagdatumTijd\"], how=\"left\")\n",
    "\n",
    "    #na values should be 0 because there are no prescriptions for tranquilizers\n",
    "    Dataset[\"DoseDiazepam\"] = Dataset[\"DoseDiazepam\"].replace(np.nan, 0, regex=True)\n",
    "    Dataset[\"DoseDiazepamPre\"] = Dataset[\"DoseDiazepamPre\"].replace(np.nan, 0, regex=True)\n",
    "    Dataset[\"DoseDiazepamPost\"] = Dataset[\"DoseDiazepamPost\"].replace(np.nan, 0, regex=True)\n",
    "    Dataset['sum'] = Dataset.apply(lambda row: row['DoseDiazepamPre'] + row['DoseDiazepamPost'], 1)\n",
    "    Dataset['diff'] = Dataset.apply(lambda row: abs(row['DoseDiazepam'] - row['sum']), 1)\n",
    "    Dataset['avg'] = Dataset.apply(lambda row: 0.5 * (row['DoseDiazepam'] + row['sum']), 1)\n",
    "    Dataset['fracdiff'] = Dataset.apply(lambda row: row['diff'] / row['avg'] if row['avg'] > 0 else 0, 1)\n",
    "    assert len(Dataset[Dataset['fracdiff'] > 0.001]) == 0\n",
    "    Dataset.drop(columns=['sum', 'diff', 'avg', 'fracdiff'], inplace=True)\n",
    "\n",
    "    # true dataset \n",
    "    DatasetWhole = Dataset[UsefullVariables]\n",
    "    \n",
    "    assert np.sum(DatasetWhole.isnull().sum().values) == 0\n",
    "    return DatasetWhole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetWhole = get_adm_dbc(1 , adm_dbc1)\n",
    "\n",
    "del DatasetWhole[\"DoseDiazepamPost\"]\n",
    "del DatasetWhole[\"DoseDiazepamPre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset14Days = get_adm_dbc(2 , adm_dbc2)\n",
    "\n",
    "del Dataset14Days[\"DoseDiazepam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset3Days = get_adm_dbc(3 , adm_dbc3)\n",
    "\n",
    "del Dataset3Days[\"DoseDiazepam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency check\n",
    "\n",
    "Check that this matches the dataset constructed by Jesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously assembled 14-day dataset\n",
    "old_14_day_dataset = pd.read_csv(DATA_DIR + 'Dataset14Days.csv')\n",
    "assert len(old_14_day_dataset) == len(Dataset14Days)\n",
    "assert set([el for el in Dataset14Days.columns]) == set([el for el in old_14_day_dataset.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dict, new_dict = [{lbl: len(grp) for lbl, grp in df.groupby('PseudoID')} for df in (old_14_day_dataset, Dataset14Days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(old_dict) == len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert old_dict.keys() == new_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len([el for el in old_dict.keys() if old_dict[el] != new_dict[el]]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset14Days['PabloID'] = Dataset14Days.apply(lambda row: '_'.join([str(int(row[el])) for el in ('PseudoID', 'Duur', 'Leeftijd_opname', 'EersteOpname', 'Klin.Acuut & Intensieve. Zorg Jeugd', 'DoseDiazepamPre')]), 1)\n",
    "old_14_day_dataset['PabloID'] = old_14_day_dataset.apply(lambda row: '_'.join([str(int(row[el])) for el in ('PseudoID', 'Duur', 'Leeftijd_opname', 'EersteOpname', 'Klin.Acuut & Intensieve. Zorg Jeugd', 'DoseDiazepamPre')]), 1)\n",
    "assert len(Dataset14Days) == Dataset14Days['PabloID'].nunique()\n",
    "assert len(old_14_day_dataset) == old_14_day_dataset['PabloID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = Dataset14Days.merge(old_14_day_dataset, on='PabloID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(merged) == len(Dataset14Days)\n",
    "assert len(merged) == len(old_14_day_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_columns = ['DoseDiazepamPre', 'DoseDiazepamPost']\n",
    "for col in special_columns:\n",
    "    assert len(merged[merged.apply(lambda row: row[col + '_x'] == row[col + '_y'] or abs(row[col + '_x'] - row[col + '_y']) * 2 / (row[col + '_x'] + row[col + '_y']) < 0.005, 1)]) == len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Dataset14Days.columns:\n",
    "    if col in special_columns or col == 'PabloID':\n",
    "        continue\n",
    "    if len(merged[merged.apply(lambda row: row[col + '_x'] != row[col + '_y'], 1)]) != 0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've gotten this far, then this notebook reproduces Jesse's dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
